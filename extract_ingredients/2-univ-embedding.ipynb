{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in docker:\n",
    "# sudo docker run -p 8890:8888 -v /home/tehdog/data/dev/2019/pic2kcal-cv-praktikum:/tf/notebooks --runtime=nvidia -it --rm tensorflow/tensorflow:1.12.0-gpu-py3 jupyter notebook --allow-root --notebook-dir=/tf/notebooks\n",
    "# crashes in TF1.4!\n",
    "# does not work with Arch Linux TF installation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.5/dist-packages (0.5.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-hub) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-hub) (1.15.4)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-hub) (3.6.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from protobuf>=3.4.0->tensorflow-hub) (40.5.0)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.5/dist-packages (0.1.82)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tf-sentencepiece in /usr/local/lib/python3.5/dist-packages (0.1.82.1)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.5/dist-packages (4.32.2)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-hub\n",
    "!pip install sentencepiece\n",
    "!pip install tf-sentencepiece\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0701 09:44:39.742711 139950204315392 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tf_sentencepiece\n",
    "\n",
    "# Set up graph.\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "  text_input = tf.placeholder(dtype=tf.string, shape=[None])\n",
    "  en_de_embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder-xling/en-de/1\")\n",
    "  embedded_text = en_de_embed(text_input)\n",
    "  init_op = tf.group([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "g.finalize()\n",
    "\n",
    "# Initialize session.\n",
    "session = tf.Session(graph=g)\n",
    "session.run(init_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import heapq\n",
    "from operator import itemgetter\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from math import ceil\n",
    "\n",
    "data_dir = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jq '.[]' fddb_data_v3.json > fddb_data_v3.jsonl\n",
    "# jq 'select(([.Bilder[]|select(.title != \"Noch kein Foto vorhanden.\")]|length) > 0)' fddb_data_v3.jsonl | jq -s > fddb_data_v3_withimg.json\n",
    "with open(str(data_dir / \"fddb_data_v3_withimg.json\"), encoding='utf-8') as f:\n",
    "    fddb = json.load(f)\n",
    "    # todo: make unique here\n",
    "    _out_names = [e[\"name\"] for e in fddb]\n",
    "\n",
    "# jq '.ingredients[]|select(.ingredient)|.ingredient' processed_data.jsonl | jq -s unique > ingredients.json\n",
    "with open(str(data_dir / \"recipes/ingredients.json\"), encoding='utf-8') as f:\n",
    "    _in_names = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ingredient(ing: str):\n",
    "    ing = re.sub(r\"\\(([^)])\\)\", \"\\g<1>\", ing)  # remove stuff in parens\n",
    "    ing = re.sub(r\"\\([^)]+\\)\", \"\", ing)  # remove stuff in parens\n",
    "    ing = re.sub(r\"(\\d+,)?\\d+ k?g\\b\", \"\", ing)  # remove xyz gram\n",
    "    ing = re.sub(r\",.*\", \"\", ing)\n",
    "    ing = re.sub(r\"\\bzum .*\", \"\", ing)\n",
    "    ing = re.sub(r\"\\boder\\b.*\", \"\", ing)\n",
    "    ing = ing.strip()\n",
    "    return ing\n",
    "\n",
    "from extract_ingredients.util import normalize_out_ingredient\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21444"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_names = list({normalize_ingredient(ing) for ing in _in_names})\n",
    "print(len(_in_names))\n",
    "in_names.sort()\n",
    "len(in_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108084"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(_out_names))\n",
    "out_names = list({ning for ing in _out_names for ning in normalize_out_ingredient(ing)})\n",
    "out_names.sort()\n",
    "len(out_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def Matcher():\n",
    "#    def __init__(self, data_left, data_right, preproc_left, preproc_right):\n",
    "#        pre_left = list(map(preproc_left, data_left))\n",
    "#        self.left_vecs = list(zip(data_left, pre_left, get_sentence_vectors(pre_left)))\n",
    "#        \n",
    "#        pre_right = list(map(preproc_right, data_right))\n",
    "#        self.right_vecs = list(zip(data_right, pre_right, get_sentence_vectors(pre_right)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chunks(l, n):\n",
    "    n = max(1, n)\n",
    "    return (l[i:i+n] for i in range(0, len(l), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vectors(texts):\n",
    "    bs = 10000\n",
    "    ccount = len(texts)//bs\n",
    "    chunks = make_chunks(texts, bs)\n",
    "    if ccount >= 3:\n",
    "        chunks = tqdm(chunks, total=ccount)\n",
    "    for chunk in chunks:\n",
    "        yield from session.run(embedded_text, feed_dict={text_input: chunk})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match(search: np.array, out_vecs, limit=10):\n",
    "    it = ((v[0], np.dot(v[1], search)) for v in out_vecs)\n",
    "    res_list = heapq.nlargest(limit, it, key=itemgetter(1))\n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ebe62b264624bce9d874e82675ef6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_vecs = list(zip(out_names, get_sentence_vectors(out_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_vecs[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('8 Kräuter', '\"DIE FEINE\" Geflügel-Fleischwurst, würzi...')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_names[0], out_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vecs = list(zip(in_names, get_sentence_vectors(in_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kräutermeersalz und Pfeffer -> ('Kräutersalz mit Meersalz', 0.8910994)\n",
      "Rosenblätter einige frische -> ('frische Lasagne-Blätter', 0.78550977)\n",
      "Butterschmalz für die Form -> ('Butterschmalz', 0.8332726)\n",
      "Erbsen . TK -> ('Erbsen, fein TK', 0.8578725)\n",
      "Hafer - Kleie -> ('Hafer Kleie', 0.93807006)\n",
      "Muffinförmchen -> ('Gebäckröllchen', 0.8753226)\n",
      "Äpfel  für die Garnitur -> ('Püree aus Äpfeln', 0.8080305)\n",
      "Rote Bete -> ('Rote Bete', 0.99999994)\n",
      "Tortenboden mit Rand -> ('Feiner Biskuit Tortenboden', 0.76696867)\n",
      "Orangenaroma -> ('Orangenlimonade', 0.8714565)\n",
      "Blumenkohl in Röschen -> ('Blumenkohl Röschen', 0.9352437)\n",
      "Zitronenmelisse zur Dekoration -> ('Zitronenmelisse', 0.79763734)\n",
      "Gartenkräuter  nach Belieben -> ('Gartenkräuter', 0.89898866)\n",
      "Garnelen  Gr. 16/20 -> ('Penne Rigate N. 19', 0.7066887)\n",
      "Puddingpulver für Grießpudding -> ('Grießpudding pur', 0.8798977)\n",
      "Eiweißbrot -> ('Eiweißbrot', 0.9999999)\n",
      "Erythrit  light -> ('Erythrit', 0.8693255)\n",
      "Joghurt Vanillegeschmack -> ('Joghurt Vanille', 0.94737524)\n",
      "Rindfleisch eine Scheibe -> ('Hamburger aus Rindfleisch', 0.86973035)\n",
      "Sauerhalbrahm -> ('Sauerrahm', 0.92483956)\n",
      "Bratensauce für Schweinebraten -> ('Hackbraten in Bratensauce', 0.91467047)\n",
      "Balsamico - crema -> ('Crema Balsamico', 0.90440506)\n",
      "Mus aus Quitten -> ('Quittengelee', 0.8808425)\n",
      "Kloßteig für rohe Klöße -> ('Kartoffel Klöße aus Fertigkloßteig', 0.87871486)\n",
      "Schweinerollbraten vom Spanferkel -> ('Spanferkelbraten aus dem Schinken', 0.9178301)\n",
      "Semmelbrösel bzw. Paniermehl nach Belieben -> ('Semmelbrösel, aus Weißbrot', 0.838044)\n",
      "Öl z. B. Walnuss- -> ('walnussöl', 0.71842754)\n",
      "Zucker und 1 Pck. Vanillezucker -> ('Vanillezucker, Zucker', 0.9038191)\n",
      "Tortellini mit Fleisch- -> ('Tortellini , Fleisch', 0.8375944)\n",
      "Sauerkraut ca. -> ('Sauerkraut', 0.79025126)\n",
      "Soja -Lezithin -> ('Soja-Reis', 0.8461486)\n",
      "Dill zur Dekoration -> ('Dill-Schnitten', 0.75840974)\n",
      "Butter  für die Form -> ('Leichte Butter', 0.8327984)\n",
      "Fenchel - Grün vom Knollenfenchel -> ('Fenchel - Anis - Kümmeltee, mild und natürlich', 0.76163256)\n",
      "Rumtopf - Früchte -> ('Früchte-Genuss', 0.82403773)\n",
      "Rhabarber bis -> ('Rhabarber', 0.855756)\n",
      "Frischkäse Balance natur -> ('Frischkäse Balance', 0.9121306)\n",
      "Kekse mit Buttergeschmack -> ('Plätzchen mit Butter und saurer Sahne', 0.8694198)\n",
      "Kasseler -> ('Kasseler', 0.99999994)\n",
      "Fertigmischung mit Mohn -> ('Rührkuchen mit Mohn', 0.8283526)\n",
      "Spargel weiß und/ -> ('Spargel, weiß', 0.8848877)\n",
      "Öl (Knoblauchöl -> ('Öl, Knoblauch', 0.86878145)\n",
      "Beeren für die Deko -> ('Beeren Traum', 0.81360507)\n",
      "Mozzarella a -> ('Mozzarella', 0.9475943)\n",
      "Honig mit -> ('Honig', 0.93344975)\n",
      "Nougatschokolade -> ('Edelkakoa-Schokolade', 0.84975743)\n",
      "Stangenweißbrote / Baguette -> ('Baguette, Weizenbrot', 0.84088135)\n",
      "Basilikum und evt. schwarze Oliven -> ('Grüne Oliven, mit Petersilie und Chili', 0.8688706)\n",
      "Trockenfrüchte z.B. Birnen -> ('Trockenobst, Pflaumen', 0.7783096)\n",
      "Toastbrot als Beilage -> ('Toast Bread', 0.8460602)\n",
      "Orangensaft nach Bedarf -> ('Orangensaft, Direktsaft', 0.84684)\n",
      "Knoblauchzehen nach Geschmack auch mehr -> ('Knoblauchecken, Knoblauch', 0.83682156)\n",
      "Mineralwasser bis 600 -> ('Mineralwasser still', 0.80440795)\n",
      "Baguettes  à 6 Stück -> ('Mini Baguettes', 0.8523272)\n",
      "Salzheringe -> ('Salzmandeln', 0.9361937)\n",
      "süße Sahne bzw. Schlagsahne -> ('kirschgrütze, mit vanille creme', 0.8266138)\n",
      "Filets vom Bison -> ('Bison Steak', 0.72254425)\n",
      "Chilischoten nach Geschmack -> ('Chilischote, frisch', 0.85557413)\n",
      "Zimt nach Geschmack -> ('Zimt gemahlen', 0.9065592)\n",
      "Zucker - Möhren -> ('Karotten - Saft', 0.87340796)\n",
      "Brühe aus Würfeln -> ('Brühwürfel', 0.9152479)\n",
      "Fenchel - Knolle -> ('Miree - Champignon', 0.77261424)\n",
      "Zucker für die Sahne -> ('Saure Sahne', 0.80789703)\n",
      "Tomatenmark je -> ('Tomatenmark', 0.91365516)\n",
      "WanTan Blätter -> ('Friesen Blätter', 0.7651035)\n",
      "Orangensaft einer Bio-Orange -> ('Bio Orange, Orangensaft', 0.91577053)\n",
      "Lammlachse à -> ('Lammlachse, mariniert', 0.8223414)\n",
      "Fett für den Formenrand -> ('Quark 3/4 Fett, Natur', 0.7206675)\n",
      "Nudelteig aus dem Kühlregal -> ('Nudelauflauf', 0.7952585)\n",
      "Frischkäse mit Pfifferlingen -> ('Frischkäse, mit französischen Kräutern', 0.8938755)\n",
      "Zuckermelonen -> ('Zuckermelone', 0.9435494)\n",
      "Misopaste . hell -> ('Mispel', 0.74611413)\n",
      "Feldsalat und / -> ('Bohnensalat +', 0.76569426)\n",
      "Sauerteig selbst hergestellt -> ('Brot selbst gebacken', 0.808918)\n",
      "Parmesan nach Geschmack -> ('Parmesan Dressing', 0.801172)\n",
      "Tequila Cuervo -> ('Sierra Tequila reposado', 0.86718786)\n",
      "Kletzen -> ('Klebreis', 0.9054465)\n",
      "Dinkelmehl Type 603 -> ('Dinkelmehl Type 630', 0.91202396)\n",
      "Gurkenflüssigkeit der Essiggurken -> ('Gurken scharf', 0.82291895)\n",
      "Blut - Wurst/Preßsack -> ('Wurstsalat - VielLeicht', 0.736675)\n",
      "Bärlauchblätter gewaschen und in feine Streifen geschnitten -> ('Halbe gelbe Schälerbsen, getrocknet und geschält', 0.69246185)\n",
      "Kräuter z. B. Peterselie -> ('Kräuter-Nockerln', 0.7612881)\n",
      "Tauben - Flügel -> ('Bunter Vogel', 0.78093666)\n",
      "Mehl fürs Backblech -> ('Backmehl', 0.83964443)\n",
      "Putenbrust in Scheiben -> ('Putenbrust-Spiesse', 0.9067554)\n",
      "Mineralwasser mit wenig Kohlensäure -> ('Mineralwasser ohne Kohlensäure', 0.9654751)\n",
      "Kirschwasser -> ('Kirschsaft', 0.9068921)\n",
      "Balsamico Bianco -> ('Balsamico Bianco', 1.0)\n",
      "Limetten - Spalten -> ('Körnerbursche', 0.76039326)\n",
      "Lebensmittelfarbe in Rosa -> ('Back und Speisefarben', 0.74058884)\n",
      "Kirschpaprika -> ('Kirschpaprika', 1.0)\n",
      "Öl und etwas mehr -> ('Öl', 0.77778304)\n",
      "Erbsen und Bohnen Mix à -> ('Erbsen und Karottem', 0.8439076)\n",
      "Woksauce -> ('Wok Sauce', 0.9069717)\n",
      "Champignons -> ('Champignons', 1.0000001)\n",
      "Pflanzenöl z.B. Rapsöl -> ('Reines Pflanzenöl, aus Raps', 0.8768829)\n",
      "Kinderschokolade -> ('Kinderschokolade', 1.0)\n",
      "Tofustange/n -> ('Tofu', 0.8247258)\n",
      "Knödel vom Vortag -> ('Semmel Knödel', 0.79959375)\n",
      "Walnüsse + -> ('Walnüsse', 0.8336214)\n"
     ]
    }
   ],
   "source": [
    "for ingredient, vec in random.sample(in_vecs, 100):\n",
    "    res_list = get_match(vec, out_vecs)\n",
    "    print(\"{} -> {}\".format(ingredient, res_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Kartoffeln', 1.0),\n",
       " ('Kartoffelstock', 0.8959534),\n",
       " ('Kartoffeln roh', 0.8905239),\n",
       " ('Kartoffeln gebacken', 0.8904908),\n",
       " ('Kartoffelscheiben', 0.8901619),\n",
       " ('Kartoffeln, ganz', 0.88885343),\n",
       " ('Kartoffel', 0.88085693),\n",
       " ('Kartoffelnudeln', 0.8792579),\n",
       " ('Gekochte Kartoffeln', 0.8718474),\n",
       " ('geschälte Kartoffeln', 0.8708629)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = [inv for inv in in_vecs if inv[0] == 'Kartoffeln'][0]\n",
    "get_match(z[1], out_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Zwiebeln', 1.0),\n",
       " ('Zwiebel', 0.9583577),\n",
       " ('Zwiebelringe', 0.9388668),\n",
       " ('Zwiebelmett', 0.9328606),\n",
       " ('Zwiebelsenf', 0.9232825),\n",
       " ('Zwiebelschmalz', 0.91526103),\n",
       " ('Rote Zwiebeln', 0.8996499),\n",
       " ('Zwiebeln, gegart', 0.8959136),\n",
       " ('Rstzwiebeln', 0.89036834),\n",
       " ('Zwiebelfleisch', 0.88157207)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = [inv for inv in in_vecs if inv[0] == 'Zwiebeln'][0]\n",
    "get_match(z[1], out_vecs, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02928fea2ef4bc4a80994a0188363da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21444), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# i thought multiprocessing is impossible in jupyter notebook?\n",
    "# better not question it\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def jsonable(e):\n",
    "    return [(a,float(b)) for a, b in e]\n",
    "\n",
    "def get_match_w(t):\n",
    "    ing, vec = t\n",
    "    return ing, get_match(vec, out_vecs)\n",
    "\n",
    "all_ings = {}\n",
    "with Pool(8) as pool:\n",
    "    for ing, match in pool.imap(get_match_w, tqdm(in_vecs), chunksize=100):\n",
    "        all_ings[ing] = jsonable(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_ings_orig = {ing: all_ings[normalize_ingredient(ing)] for ing in _in_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/recipe-ingredient-to-fooddb.json\", \"w\") as f:\n",
    "    json.dump(all_ings_orig, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
