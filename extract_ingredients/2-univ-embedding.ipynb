{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in docker:\n",
    "# sudo docker run -p 8890:8888 -v /home/tehdog/data/dev/2019/pic2kcal-cv-praktikum:/tf/notebooks --runtime=nvidia -it --rm tensorflow/tensorflow:1.12.0-gpu-py3 jupyter notebook --allow-root --notebook-dir=/tf/notebooks\n",
    "# crashes in TF1.4!\n",
    "# does not work with Arch Linux TF installation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.5/dist-packages (0.5.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-hub) (1.11.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-hub) (3.6.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-hub) (1.15.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from protobuf>=3.4.0->tensorflow-hub) (40.5.0)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.5/dist-packages (0.1.82)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tf-sentencepiece in /usr/local/lib/python3.5/dist-packages (0.1.82.1)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.5/dist-packages (4.32.2)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-hub\n",
    "!pip install sentencepiece\n",
    "!pip install tf-sentencepiece\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0707 18:02:29.588741 139647363516160 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tf_sentencepiece\n",
    "\n",
    "# Set up graph.\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "  text_input = tf.placeholder(dtype=tf.string, shape=[None])\n",
    "  en_de_embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder-xling/en-de/1\")\n",
    "  embedded_text = en_de_embed(text_input)\n",
    "  init_op = tf.group([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "g.finalize()\n",
    "\n",
    "# Initialize session.\n",
    "session = tf.Session(graph=g)\n",
    "session.run(init_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import heapq\n",
    "from operator import itemgetter\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from math import ceil\n",
    "\n",
    "data_dir = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jq '.[]' fddb_data_v3.json > fddb_data_v3.jsonl\n",
    "# jq 'select(([.Bilder[]|select(.title != \"Noch kein Foto vorhanden.\")]|length) > 0)' fddb_data_v3.jsonl | jq -s > fddb_data_v3_withimg.json\n",
    "with open(str(data_dir / \"fddb_data_v4_withimg.json\"), encoding='utf-8') as f:\n",
    "    fddb = json.load(f)\n",
    "    # todo: make unique here\n",
    "    _out_names = [e[\"name\"] for e in fddb]\n",
    "\n",
    "# jq '.ingredients[]|select(.ingredient)|.ingredient' processed_data.jsonl | jq -s unique > ingredients.json\n",
    "with open(str(data_dir / \"recipes/ingredients.json\"), encoding='utf-8') as f:\n",
    "    _in_names = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ingredient(ing: str):\n",
    "    ing = re.sub(r\"\\(([^)])\\)\", \"\\g<1>\", ing)  # remove stuff in parens\n",
    "    ing = re.sub(r\"\\([^)]+\\)\", \"\", ing)  # remove stuff in parens\n",
    "    ing = re.sub(r\"(\\d+,)?\\d+ k?g\\b\", \"\", ing)  # remove xyz gram\n",
    "    ing = re.sub(r\",.*\", \"\", ing)\n",
    "    ing = re.sub(r\"\\bzum .*\", \"\", ing)\n",
    "    ing = re.sub(r\"\\boder\\b.*\", \"\", ing)\n",
    "    ing = ing.strip()\n",
    "    return ing\n",
    "\n",
    "from extract_ingredients.util import normalize_out_ingredient\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21444"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_names = list({normalize_ingredient(ing) for ing in _in_names})\n",
    "print(len(_in_names))\n",
    "in_names.sort()\n",
    "len(in_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108086"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(_out_names))\n",
    "out_names = list({ning for ing in _out_names for ning in normalize_out_ingredient(ing)})\n",
    "out_names.sort()\n",
    "len(out_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def Matcher():\n",
    "#    def __init__(self, data_left, data_right, preproc_left, preproc_right):\n",
    "#        pre_left = list(map(preproc_left, data_left))\n",
    "#        self.left_vecs = list(zip(data_left, pre_left, get_sentence_vectors(pre_left)))\n",
    "#        \n",
    "#        pre_right = list(map(preproc_right, data_right))\n",
    "#        self.right_vecs = list(zip(data_right, pre_right, get_sentence_vectors(pre_right)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chunks(l, n):\n",
    "    n = max(1, n)\n",
    "    return (l[i:i+n] for i in range(0, len(l), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vectors(texts):\n",
    "    bs = 10000\n",
    "    ccount = len(texts)//bs\n",
    "    chunks = make_chunks(texts, bs)\n",
    "    if ccount >= 3:\n",
    "        chunks = tqdm(chunks, total=ccount)\n",
    "    for chunk in chunks:\n",
    "        yield from session.run(embedded_text, feed_dict={text_input: chunk})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match(search: np.array, out_vecs, limit=30):\n",
    "    it = ((v[0], np.dot(v[1], search)) for v in out_vecs)\n",
    "    res_list = heapq.nlargest(limit, it, key=itemgetter(1))\n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad15c95122bf48aaa8cb31cee697cd29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_vecs = list(zip(out_names, get_sentence_vectors(out_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_vecs[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('8 Kräuter', '\"DIE FEINE\" Geflügel-Fleischwurst, würzi...')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_names[0], out_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vecs = list(zip(in_names, get_sentence_vectors(in_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chiliflocken aus der Mühle -> ('Kirschstreusel', 0.7449405)\n",
      "Rosmarin . frischer -> ('Rosmarin, frisch', 0.9431499)\n",
      "Mehl nach Bedarf -> ('Zopfmehl', 0.80514395)\n",
      "Zartbitterschokolade 70 % Kakaoanteil -> ('Bitterschokolade 70 % Kakaogehalt', 0.89710546)\n",
      "Frischkäse bis 1 % Fett absolut -> ('Weichkäse, 13% Fett absolut', 0.8758312)\n",
      "Vollkornnudeln Dinkelvollkornspiralspätzle -> ('Dinkelvollkorn Bauernspätzle', 0.90983033)\n",
      "Piri-Piri aus dem Glas -> ('Piri-Piri, feurig scharf', 0.74664783)\n",
      "Hirschfleisch aus der Keule -> ('Schabefleisch vom Rind', 0.8933994)\n",
      "Kräuter für die Crème fraiche -> ('Crème fraiche mit Kräuter', 0.8813894)\n",
      "Brotaufstrich Paprika Peperoni -> ('Paprika&Peperoni Brotaufstrich', 0.9281652)\n",
      "Rettiche und Kohlrabi -> ('Kohlrabi-Gemüse', 0.8378093)\n",
      "Kürbisfleisch zu Mus gekocht und abgetropft -> ('Kürbiskerne, geröstet und gesalzen', 0.8433009)\n",
      "Reh - Knochen aus der Keule -> ('Rinder-Gulasch aus der Keule', 0.77878106)\n",
      "Chorizo -> ('Chorizo', 0.9999998)\n",
      "Spätzle aus dem Kühlregal -> ('Spätzle gekocht', 0.80079585)\n",
      "Äpfel mit Schale -> ('Äpfel mit Bananen', 0.87620306)\n",
      "Lecithin -> ('Lecithin-Granulat', 0.8970465)\n",
      "Zimt - Aroma -> ('Zimt gemahlen', 0.872457)\n",
      "Kokoscreme aus der Dose -> ('Kokoscreme', 0.92384195)\n",
      "Palmfett z. B. Palmin -> ('Kokosfett', 0.729101)\n",
      "Quitten - Fruchtfleisch ca. -> ('Fruchtgelee, Quitte', 0.6065817)\n",
      "Zitronen - abgeriebene Schale -> ('Zitronenschale gerieben', 0.9382094)\n",
      "Knoblauch - gewürz -> ('Knoblauchpüree', 0.91742337)\n",
      "Basilikumblätter ich nehme immer recht viel -> ('Basilikum, frisch', 0.73645645)\n",
      "Zucker für das Parfait -> ('Raffinade Zucker', 0.8011861)\n",
      "Früchte z. B. Himbeeren -> ('Apfel Himbeere, und andere Früchte', 0.80654204)\n",
      "Parmesan gerieben -> ('Parmesankäse, gerieben', 0.87060416)\n",
      "Pizzagewürz - je nach Geschmack -> ('Pizzagewürz', 0.9084599)\n",
      "Weißbrot ohne Kruste -> ('Vollkornbrot ohne Kruste', 0.92591876)\n",
      "Romanasalat - Herzen -> ('Romanasalat', 0.88115346)\n",
      "Aroma für Eiweißpulver -> ('Eiweißpulver', 0.8932079)\n",
      "Kirschsaft von den abgetropften Kirschen -> ('Sauerkirschen getrocknet, Kirsche', 0.85626256)\n",
      "Zitronensaft von 2 -> ('Zitronensaft', 0.87135446)\n",
      "Fleur de Sel und Pfeffer nach Belieben -> ('Pfefferbeißer, Herzhaft Geräuchert', 0.69992316)\n",
      "Butter von Kühen -> ('Feta aus Kuhmilch', 0.8292722)\n",
      "Gemüsemischung China Art -> ('Gemüsemischung, Asiatische Art', 0.9102745)\n",
      "Eigelb und 1 EL Wasser -> ('Eigelb', 0.79483944)\n",
      "Brote - Boden -> ('Knäckebrot - Vollkorn', 0.8170699)\n",
      "Löwenzahnblüten -> ('Löwenzahntee', 0.9499061)\n",
      "Ackee -> ('Edamer', 0.82985467)\n",
      "Puderzucker eine kreisrunde Marzipanplatte herstellen -> ('Roh-Rohrzucker Würfelzucker', 0.7915075)\n",
      "Senf und 1/2 TL Tomatenmark -> ('Senf & Meerrettich, Senf', 0.8237603)\n",
      "Semmeln - Knödel vom Vortag -> ('Semmel Knödel, der Klassiker', 0.88499826)\n",
      "Ras el Hanout Paste -> ('Ras el Hanout', 0.89237773)\n",
      "Lamm - Keule. ca. -> ('Lammspieße', 0.6884059)\n",
      "Baby-Romanasalat -> ('Mini Romanasalat', 0.8288654)\n",
      "Arrak für den Guss -> ('Sanddorn elixier', 0.60732317)\n",
      "Gurken -Aufguss-Konzentrat -> ('Gurkenfrisch', 0.822387)\n",
      "Tortencreme mit Vanillegeschmack -> ('Dessertcreme mit Sahne, Vanille', 0.874184)\n",
      "Zitronat -> ('Zitronat', 0.99999976)\n",
      "Salz nach Belieben -> ('Gut Salzig', 0.8407154)\n",
      "Marzipan - Rosen -> ('Van Danken - Butterkuchen', 0.8203522)\n",
      "Direktsaft  aus dem Kühlregal -> ('Orangensaft (aus dem Kühlregal)', 0.692865)\n",
      "Joghurt  à -> ('Frappe, Joghurt', 0.91313946)\n",
      "Fusilli integrale -> ('Fusilli integrale', 0.9999999)\n",
      "Hühnerbrust -> ('Hühnerbrust', 1.0)\n",
      "Schmelzkäse od. Backofenkäse -> ('Backofen Leberkäse Käse', 0.9276445)\n",
      "Kirschtomaten bzw. Cocktailtomaten -> ('Kirschtomaten mit scharfe chilischote', 0.83049256)\n",
      "Kürbiskernöl - gute Qualität -> ('Kürbiskernöl', 0.86616856)\n",
      "Minutenschnitzel von Hähnchenfleisch -> ('Minutenschnitzel Hähnchen', 0.95446366)\n",
      "Zimt - zucker -> ('Zimt', 0.90005577)\n",
      "Sahne mit Eiskaffeepulver aufgeschlagen -> ('Kaffee mit Milchpulver, Kaffee', 0.85928524)\n",
      "Mayonnaise aus der Tube nach Bedarf -> ('Einfach Lecker Mayonnaise', 0.7130511)\n",
      "Weizengras -> ('Weizengras', 1.0)\n",
      "Käse - Ersatz -> ('Käsemischung', 0.8279395)\n",
      "Lauch / Zwiebeln -> ('Frühlingszwiebel / Lauchzwiebel', 0.863052)\n",
      "Zitronensäure aus der Apotheke -> ('Zitronensaft aus Zitronensaftkonzentrat', 0.81886834)\n",
      "Baguettes mit Kräuterbutter aus dem Kühlregal -> ('Baguette, mit Kräuterbutter', 0.84031343)\n",
      "Oliven und Thymian -> ('Oliven mit Mandeln', 0.8566104)\n",
      "Kräuter  aus dem Gewürzregal -> ('Kräuter-Schinken', 0.82669127)\n",
      "Zuckercouleur -> ('Zuckerbrezel', 0.8405626)\n",
      "Hähnchenkeulen je ca. -> ('Hähnchenunterkeulen', 0.6988278)\n",
      "Thymian und Majoran -> ('Thym & Sel, Thymian und Salz', 0.828655)\n",
      "Butterschmalz für die Bratwurst -> ('Grobe Bratwurst', 0.8740183)\n",
      "Beeren - Nuss-Mix -> ('Beeren-Nuss  Mix', 0.8902206)\n",
      "Paprika-Würzpaste -> ('Paprikasülze', 0.9066488)\n",
      "Maniok - Mehl -> ('Pita - Brot', 0.7835018)\n",
      "Weizen - -> ('Weizen', 0.94974315)\n",
      "Gurkenessig  fix und fertig -> ('Möhren gekocht und mariniert, fix und fertig', 0.74854743)\n",
      "Bärlauchcreme -> ('Bärlauch-Creme', 0.9228903)\n",
      "Sesam -> ('Sesam', 1.0)\n",
      "Gemüsebrühe und etwas Milch -> ('Gemüsebrühe, Gemüse', 0.8532828)\n",
      "Erdbeersirup -> ('Erdbeer-Sahne', 0.93891)\n",
      "Blüten vom Löwenzahn -> ('Löwenzahntee', 0.8750901)\n",
      "Mehl Gewicht der Eier -> ('Eiweiß Pfannkuchen', 0.7879802)\n",
      "Pflaumen /Zwetschgen -> ('Pflaumen', 0.8730244)\n",
      "Zanderfilets à ca. 100 - -> ('Zanderfilets', 0.6855762)\n",
      "Mandelsplitter nach Belieben -> ('Mandeln gesplittert', 0.8944701)\n",
      "Fruchtsaft ohne Zuckerzusatz -> ('Frucht Cocktail, ohne Zuckerzusatz', 0.90085447)\n",
      "Dorsch -> ('Dorsch', 1.0)\n",
      "Crème fraîche à ca. 150 - -> (\"Salami à l'ail 150g\", 0.6967076)\n",
      "Mandeln  für den Rand -> ('Mandeln ganz', 0.8877977)\n",
      "Wurzelwerk nach Geschmack -> ('Wurzelkraft', 0.84139967)\n",
      "Antipasti 1 : -> ('Pesto verde', 0.61716586)\n",
      "Blätterteig gerollt -> ('Blätterteig-Taschen', 0.87810516)\n",
      "Flüssigkeit aus der Maisdose -> ('Süßstoff flüssig', 0.76604474)\n",
      "Äpfel Bio- -> ('Apfelsüsse Bio', 0.78802574)\n",
      "Frischkäse à la Kräuter der Provence -> ('Französischer Landkäse m Kräutern der Provence', 0.91611546)\n",
      "Bambusstreifen aus dem Glas -> ('Bambus-Sprossen in Scheiben', 0.8456132)\n",
      "Mehl für den Vorteig -> ('Paniermehl', 0.84846926)\n"
     ]
    }
   ],
   "source": [
    "for ingredient, vec in random.sample(in_vecs, 100):\n",
    "    res_list = get_match(vec, out_vecs)\n",
    "    print(\"{} -> {}\".format(ingredient, res_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Kartoffeln', 1.0),\n",
       " ('Kartoffelstock', 0.8959534),\n",
       " ('Kartoffeln roh', 0.8905239),\n",
       " ('Kartoffeln gebacken', 0.8904908),\n",
       " ('Kartoffelscheiben', 0.8901619),\n",
       " ('Kartoffeln, ganz', 0.88885343),\n",
       " ('Kartoffel', 0.88085693),\n",
       " ('Kartoffelnudeln', 0.8792579),\n",
       " ('Gekochte Kartoffeln', 0.8718474),\n",
       " ('geschälte Kartoffeln', 0.8708629),\n",
       " ('Kartoffel Sticks', 0.8684819),\n",
       " ('Kartoffeln mehlig', 0.86703193),\n",
       " ('Kartoffelklöße', 0.8620798),\n",
       " ('Kartoffelpürree', 0.86069757),\n",
       " ('Kartoffelpüree', 0.8605306),\n",
       " ('Kartoffeln rot', 0.8586046),\n",
       " ('Kartoffeltopf', 0.85467523),\n",
       " ('Kartoffelspalten', 0.8534164),\n",
       " ('Kartoffeln festkochend', 0.85249126),\n",
       " ('Kartoffelteig', 0.8495877),\n",
       " ('Kartoffeln in Scheiben', 0.8480123),\n",
       " ('Kartoffeln (fertig)', 0.8420578),\n",
       " ('Kartoffelcreme', 0.8384942),\n",
       " ('Kartoffelmehl', 0.8381945),\n",
       " ('Kartoffelbüsch', 0.8379458),\n",
       " ('Kartoffeln -  ganz', 0.83605176),\n",
       " ('Kartoffelbrei', 0.83593315),\n",
       " ('Kartoffel-Pürree', 0.8321384),\n",
       " ('Kartoffel-Püree', 0.8320216),\n",
       " ('Bratkartoffeln', 0.8299942)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = [inv for inv in in_vecs if inv[0] == 'Kartoffeln'][0]\n",
    "get_match(z[1], out_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Schalotten', 1.0000001),\n",
       " ('Sülze', 0.89274013),\n",
       " ('Ringlotten', 0.8788649),\n",
       " ('Schaschlik', 0.8767235),\n",
       " ('Leberkse', 0.87103057),\n",
       " ('Schwartenmagen', 0.86798453),\n",
       " ('Maiskölbchen', 0.86279553),\n",
       " ('Grützwust', 0.8598486),\n",
       " ('Maisecke', 0.85870075),\n",
       " ('Käsknacker', 0.858381),\n",
       " ('Hhnerfilet', 0.8569063),\n",
       " ('Korneck', 0.85655665),\n",
       " ('Körnereck', 0.8554502),\n",
       " ('Landschinken', 0.85422593),\n",
       " ('Rohschinken', 0.8509237),\n",
       " ('Karreespeck', 0.85052764),\n",
       " ('Wafer', 0.84980637),\n",
       " ('Kräcker', 0.8489746),\n",
       " ('Radieschen', 0.84836495),\n",
       " ('Rehgulasch', 0.8480122),\n",
       " ('Kareespeck', 0.8477373),\n",
       " ('Rohesser', 0.846316),\n",
       " ('Körnerbursche', 0.8454909),\n",
       " ('Mairübchen', 0.8453922),\n",
       " ('Rettich', 0.8451376),\n",
       " ('Jausenspeck', 0.8450292),\n",
       " ('Kaisersemmeln', 0.8447572),\n",
       " ('Stelline', 0.84436196),\n",
       " ('Palatschinken', 0.8443409),\n",
       " ('Mohnstuten', 0.84411025)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = list(get_sentence_vectors([\"Schalotten\"]))[0]\n",
    "get_match(z, out_vecs, limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Salz', 1.0),\n",
       " ('Salzgurken', 0.9089097),\n",
       " ('Gut Salzig', 0.90342623),\n",
       " ('Salzbrezeln', 0.8880923),\n",
       " ('Salzgurken, salzig', 0.8686831),\n",
       " ('Salzmandeln', 0.8676863),\n",
       " ('Salzbrezeln, Salzig', 0.8605131),\n",
       " ('Salzbrezel', 0.8582727),\n",
       " ('Salz-Mandeln', 0.85328484),\n",
       " ('salzbrezel', 0.84165347),\n",
       " ('Salz, Jodsalz', 0.8251066),\n",
       " ('Salzbutter', 0.81924367),\n",
       " ('Salzdillgurken', 0.8158475),\n",
       " ('Jod Salz', 0.81424797),\n",
       " ('Salz flutes, Salz', 0.8119249),\n",
       " ('Blutdruck Salz', 0.8090307),\n",
       " ('Salz-Stangen', 0.80218107),\n",
       " ('smorbar gesalzen', 0.7952043),\n",
       " ('Chips Salz', 0.79345155),\n",
       " ('Salzstangerl', 0.7885661),\n",
       " ('Salz Kräcker', 0.7803569),\n",
       " ('Corn, salz', 0.7801466),\n",
       " ('Salz Stangen', 0.7790837),\n",
       " ('Salzige Heringe', 0.7762423),\n",
       " ('Salzmandeln, geröstet gesalzen', 0.76485217),\n",
       " ('Streichzart, gesalzen', 0.76328605),\n",
       " ('Saltletts', 0.7625023),\n",
       " ('Salz-Schneidebohnen', 0.76154387),\n",
       " ('Salzstangen', 0.7579998),\n",
       " ('Salz-Cashews', 0.7565831)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = list(get_sentence_vectors([normalize_ingredient(\"Salz\")]))[0]\n",
    "get_match(z, out_vecs, limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Möhren', 0.9999998),\n",
       " ('Möhrchen', 0.9716229),\n",
       " ('Möhrenaufstrich', 0.91976905),\n",
       " ('Möhreneintopf', 0.9090408),\n",
       " ('Möhreneintopf ', 0.9090408),\n",
       " ('Karotten', 0.90865445),\n",
       " ('Möhrengemüse', 0.9066272),\n",
       " ('Möhren-Eintopf', 0.8989031),\n",
       " ('Möhren Eintopf', 0.8960131),\n",
       " ('möhreneintopf', 0.8826865),\n",
       " ('Möhrenbrötchen', 0.8769465),\n",
       " ('Karotteneintopf', 0.8718132),\n",
       " ('Karotten / Möhren', 0.86903),\n",
       " ('Möhrensaft', 0.86823654),\n",
       " ('Karottenscheiben', 0.86586285),\n",
       " ('Babymöhren', 0.8603344),\n",
       " ('Karottenbrot', 0.86014485),\n",
       " ('baby möhren', 0.85710764),\n",
       " ('junge Möhrchen', 0.8510489),\n",
       " ('Karottensaft', 0.8468522),\n",
       " ('Karottenciabatta', 0.84540284),\n",
       " ('Möhren-Eiweiß-Brot', 0.83676785),\n",
       " ('Karottenwürfel', 0.8357495),\n",
       " ('Karotten gebraten', 0.83498985),\n",
       " ('Gemüsebrei', 0.8288224),\n",
       " ('Karotten-Salat', 0.8278241),\n",
       " ('Möhrchen-Liebe', 0.8260028),\n",
       " ('Blätterteig', 0.824074),\n",
       " ('Gurkentopf', 0.82374495),\n",
       " ('Erbsen & Möhren', 0.82353055)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = list(get_sentence_vectors([normalize_ingredient(\"Möhre(n)\")]))[0]\n",
    "get_match(z, out_vecs, limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe972cb15ead479bb7ece478a61c845f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21444), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# i thought multiprocessing is impossible in jupyter notebook?\n",
    "# better not question it\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def jsonable(e):\n",
    "    return [(a,float(b)) for a, b in e]\n",
    "\n",
    "def get_match_w(t):\n",
    "    ing, vec = t\n",
    "    return ing, get_match(vec, out_vecs)\n",
    "\n",
    "all_ings = {}\n",
    "with Pool(8) as pool:\n",
    "    for ing, match in pool.imap(get_match_w, tqdm(in_vecs), chunksize=100):\n",
    "        all_ings[ing] = jsonable(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_ings_orig = {ing: all_ings[normalize_ingredient(ing)] for ing in _in_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/recipe-ingredient-to-fooddb.json\", \"w\") as f:\n",
    "    json.dump(all_ings_orig, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
