# calculates the performance of a baseline method for calorie / nutrient prediction on our dataset
#
# two baseline methods are implemented:
#
# 1. mean baseline: always predicts the value that is the average value in the dataset
# 2. random-choice baseline: chose a random recipe from the dataset and use its values as the prediction
#    Since the dataset is large enough that hitting the specific correct recipe is very unlikely, this is basically the same as predicting a random value with the mean and variance of the dataset - which has worse performance than simply always predicting the mean.
#
from pathlib import Path
import json
import numpy as np
import argparse
import random

parser = argparse.ArgumentParser()
# parser.add_argument("--runname", help="name this experiment", required=True)
parser.add_argument(
    "--datadir",
    help="input data dir generated by data/split.py (contains e.g. train.json and train/",
    required=True,
)
args = parser.parse_args()

dir = Path(args.datadir)

with open(dir / "train.json") as f:
    train = json.load(f)["data"]


def criterion_rel_error(pred, truth):
    import numpy as torch

    # https://en.wikipedia.org/wiki/Approximation_error
    ret = torch.abs(1 - pred / truth)
    ret[torch.isnan(ret)] = 0  # if truth = 0 relative error is undefined
    return torch.mean(ret)


def get_mean_baseline_model(train_values):
    print("using MEAN baseline")
    mean = np.mean(train_values)

    def model():
        return mean

    return model


def get_random_choice_baseline_model(train_values):
    print("using RANDOM CHOICE baseline")

    def model():
        return random.choice(train_values)

    return model


for key in train[0].keys():
    if key not in ["kcal", "protein", "fat", "carbohydrates", "mass_per_portion"]:
        continue
    ground_truths = [e[key] for e in train]

    mean = np.mean(ground_truths)
    std = np.std(ground_truths)
    print(f"{key} mean: {mean:.1f}")
    print(f"{key} std: {std:.1f}")

    with open(dir / "val.json") as f:
        test = json.load(f)["data"]

    baseline_model = get_random_choice_baseline_model(ground_truths)

    # baseline_model = get_mean_baseline_model(ground_truths)

    l1_train = np.mean(
        np.abs([ground_truth - baseline_model() for ground_truth in ground_truths])
    )

    ground_truths_val = [e[key] for e in test]
    l1_val = np.mean(
        np.abs([ground_truth - baseline_model() for ground_truth in ground_truths_val])
    )
    rel_val = criterion_rel_error(
        np.array([baseline_model() for ground_truth in ground_truths_val]),
        ground_truths_val,
    )
    print(f"{key} l1_train: {l1_train:.3g}")
    print(f"{key} l1_val: {l1_val:.3g}")
    print(f"{key} rel_error_val {rel_val:.3g}")
