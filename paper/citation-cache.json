{
	"https://dl.acm.org/citation.cfm?id=3297871": {
		"fetched": "2019-08-02T18:38:03.513Z",
		"bibtex": "\n@inproceedings{chokr_calories_2017,\n\taddress = {San Francisco, California, USA},\n\tseries = {{AAAI}'17},\n\ttitle = {Calories {Prediction} from {Food} {Images}},\n\turl = {http://dl.acm.org/citation.cfm?id=3297863.3297871},\n\tabstract = {Calculating the amount of calories in a given food item is now a common task. We propose a machine-learning-based approach to predict the amount of calories from food images. Our system does not require any input from the user, except from an image of the food item. We take a pragmatic approach to accurately predict the amount of calories in a food item and solve the problem in three phases. First, we identify the type of the food item in the image. Second, we estimate the size of the food item in grams. Finally, by taking into consideration the output of the first two phases, we predict the amount of calories in the photographed food item. All these three phases are based purely on supervised machine-learning. We show that this pipelined approach is very effective in predicting the amount of calories in a food item as compared to baseline approaches which directly predicts the amount of calories from the image.},\n\turldate = {2019-08-02},\n\tbooktitle = {Proceedings of the {Thirty}-{First} {AAAI} {Conference} on {Artificial} {Intelligence}},\n\tpublisher = {AAAI Press},\n\tauthor = {Chokr, Manal and Elbassuoni, Shady},\n\tyear = {2017},\n\tpages = {4664--4669}\n}",
		"csl": {
			"publisher-place": "San Francisco, California, USA",
			"collection-title": "AAAI'17",
			"title": "Calories <span class=\"nocase\">Prediction</span> from <span class=\"nocase\">Food</span> <span class=\"nocase\">Images</span>",
			"URL": "http://dl.acm.org/citation.cfm?id=3297863.3297871",
			"container-title": "Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence",
			"publisher": "AAAI Press",
			"author": [
				{
					"given": "Manal",
					"family": "Chokr"
				},
				{
					"given": "Shady",
					"family": "Elbassuoni"
				}
			],
			"page": "4664-4669",
			"type": "paper-conference",
			"citation-label": "chokr_calories_2017",
			"id": "https://dl.acm.org/citation.cfm?id=3297871",
			"issued": {
				"date-parts": [
					[
						2017
					]
				]
			}
		}
	},
	"https://dl.acm.org/citation.cfm?doid=3126686.3126742": {
		"fetched": "2019-08-02T18:41:47.387Z",
		"bibtex": "\n@inproceedings{ege_image-based_2017,\n\taddress = {New York, NY, USA},\n\tseries = {Thematic {Workshops} '17},\n\ttitle = {Image-{Based} {Food} {Calorie} {Estimation} {Using} {Knowledge} on {Food} {Categories}, {Ingredients} and {Cooking} {Directions}},\n\tisbn = {9781450354165},\n\turl = {http://doi.acm.org/10.1145/3126686.3126742},\n\tdoi = {10.1145/3126686.3126742},\n\tabstract = {Image-based food calorie estimation is crucial to diverse mobile applications for recording everyday meal. However, some of them need human help for calorie estimation, and even if it is automatic, food categories are often limited or images from multiple viewpoints are required. Then, it is not yet achieved to estimate food calorie with practical accuracy and estimating food calories from a food photo is an unsolved problem. Therefore, in this paper, we propose estimating food calorie from a food photo by simultaneous learning of food calories, categories, ingredients and cooking directions using deep learning. Since there exists a strong correlation between food calories and food categories, ingredients and cooking directions information in general, we expect that simultaneous training of them brings performance boosting compared to independent single training. To this end, we use a multi-task CNN [1]. In addition, in this research, we construct two kinds of datasets that is a dataset of calorie-annotated recipe collected from Japanese recipe sites on the Web and a dataset collected from an American recipe site. In this experiment, we trained multi-task and single-task CNNs. As a result, the multi-task CNN achieved the better performance on both food category estimation and food calorie estimation than single-task CNNs. For the Japanese recipe dataset, by introducing a multi-task CNN, 0.039 were improved on the correlation coefficient, while for the American recipe dataset, 0.090 were raised compared to the result by the single-task CNN.},\n\turldate = {2019-08-02},\n\tbooktitle = {Proceedings of the on {Thematic} {Workshops} of {ACM} {Multimedia} 2017},\n\tpublisher = {ACM},\n\tauthor = {Ege, Takumi and Yanai, Keiji},\n\tyear = {2017},\n\tkeywords = {calorie estimation, food recognition, multi-task cnn},\n\tpages = {367--375}\n}",
		"csl": {
			"publisher-place": "New York, NY, USA",
			"collection-title": "Thematic Workshops '17",
			"title": "Image-<span class=\"nocase\">Based</span> <span class=\"nocase\">Food</span> <span class=\"nocase\">Calorie</span> <span class=\"nocase\">Estimation</span> <span class=\"nocase\">Using</span> <span class=\"nocase\">Knowledge</span> on <span class=\"nocase\">Food</span> <span class=\"nocase\">Categories</span>, <span class=\"nocase\">Ingredients</span> and <span class=\"nocase\">Cooking</span> <span class=\"nocase\">Directions</span>",
			"ISBN": "9781450354165",
			"URL": "http://doi.acm.org/10.1145/3126686.3126742",
			"DOI": "10.1145/3126686.3126742",
			"container-title": "Proceedings of the on Thematic Workshops of ACM Multimedia 2017",
			"publisher": "ACM",
			"author": [
				{
					"given": "Takumi",
					"family": "Ege"
				},
				{
					"given": "Keiji",
					"family": "Yanai"
				}
			],
			"page": "367-375",
			"type": "paper-conference",
			"citation-label": "ege_image-based_2017",
			"id": "https://dl.acm.org/citation.cfm?doid=3126686.3126742",
			"issued": {
				"date-parts": [
					[
						2017
					]
				]
			}
		}
	},
	"https://arxiv.org/abs/1812.06164": {
		"fetched": "2019-08-02T18:50:23.770Z",
		"bibtex": "\n@article{romero_inverse_2018,\n\ttitle = {Inverse {Cooking}: {Recipe} {Generation} from {Food} {Images}},\n\tshorttitle = {Inverse {Cooking}},\n\turl = {https://arxiv.org/abs/1812.06164v2},\n\tabstract = {People enjoy food photography because they appreciate food. Behind each meal\nthere is a story described in a complex recipe and, unfortunately, by simply\nlooking at a food image we do not have access to its preparation process.\nTherefore, in this paper we introduce an inverse cooking system that recreates\ncooking recipes given food images. Our system predicts ingredients as sets by\nmeans of a novel architecture, modeling their dependencies without imposing any\norder, and then generates cooking instructions by attending to both image and\nits inferred ingredients simultaneously. We extensively evaluate the whole\nsystem on the large-scale Recipe1M dataset and show that (1) we improve\nperformance w.r.t. previous baselines for ingredient prediction; (2) we are\nable to obtain high quality recipes by leveraging both image and ingredients;\n(3) our system is able to produce more compelling recipes than retrieval-based\napproaches according to human judgment. We make code and models publicly\navailable.},\n\tlanguage = {en},\n\turldate = {2019-08-02},\n\tauthor = {Romero, Adriana and Giro-i-Nieto, Xavier and Drozdzal, Michal and Salvador, Amaia},\n\tmonth = dec,\n\tyear = {2018}\n}",
		"csl": {
			"title": "Inverse <span class=\"nocase\">Cooking</span>: <span class=\"nocase\">Recipe</span> <span class=\"nocase\">Generation</span> from <span class=\"nocase\">Food</span> <span class=\"nocase\">Images</span>",
			"URL": "https://arxiv.org/abs/1812.06164v2",
			"language": "en",
			"author": [
				{
					"given": "Adriana",
					"family": "Romero"
				},
				{
					"given": "Xavier",
					"family": "Giro-i-Nieto"
				},
				{
					"given": "Michal",
					"family": "Drozdzal"
				},
				{
					"given": "Amaia",
					"family": "Salvador"
				}
			],
			"type": "article-journal",
			"citation-label": "romero_inverse_2018",
			"id": "https://arxiv.org/abs/1812.06164",
			"issued": {
				"date-parts": [
					[
						2018,
						12
					]
				]
			}
		}
	},
	"https://ndb.nal.usda.gov/ndb/": {
		"fetched": "2019-08-04T15:36:36.014Z",
		"bibtex": "\n@misc{noauthor_usda_nodate,\n\ttitle = {{USDA} {Food} {Composition} {Databases}},\n\turl = {https://ndb.nal.usda.gov/ndb/},\n\tabstract = {United States Department of Agriculture Food Composition Databases},\n\turldate = {2019-08-04},\n\tjournal = {ndb.nal.usda.gov}\n}",
		"csl": {
			"title": "<span class=\"nocase\">USDA</span> <span class=\"nocase\">Food</span> <span class=\"nocase\">Composition</span> <span class=\"nocase\">Databases</span>",
			"URL": "https://ndb.nal.usda.gov/ndb/",
			"container-title": "ndb.nal.usda.gov",
			"type": "book",
			"citation-label": "noauthor_usda_nodate",
			"id": "https://ndb.nal.usda.gov/ndb/"
		}
	},
	"https://arxiv.org/abs/1607.04606": {
		"fetched": "2019-08-04T15:57:12.817Z",
		"bibtex": "\n@article{mikolov_enriching_2016,\n\ttitle = {Enriching {Word} {Vectors} with {Subword} {Information}},\n\turl = {https://arxiv.org/abs/1607.04606v2},\n\tabstract = {Continuous word representations, trained on large unlabeled corpora are\nuseful for many natural language processing tasks. Popular models that learn\nsuch representations ignore the morphology of words, by assigning a distinct\nvector to each word. This is a limitation, especially for languages with large\nvocabularies and many rare words. In this paper, we propose a new approach\nbased on the skipgram model, where each word is represented as a bag of\ncharacter \\$n\\$-grams. A vector representation is associated to each character\n\\$n\\$-gram; words being represented as the sum of these representations. Our\nmethod is fast, allowing to train models on large corpora quickly and allows us\nto compute word representations for words that did not appear in the training\ndata. We evaluate our word representations on nine different languages, both on\nword similarity and analogy tasks. By comparing to recently proposed\nmorphological word representations, we show that our vectors achieve\nstate-of-the-art performance on these tasks.},\n\tlanguage = {en},\n\turldate = {2019-08-04},\n\tauthor = {Mikolov, Tomas and Joulin, Armand and Grave, Edouard and Bojanowski, Piotr},\n\tmonth = jul,\n\tyear = {2016}\n}",
		"csl": {
			"title": "Enriching <span class=\"nocase\">Word</span> <span class=\"nocase\">Vectors</span> with <span class=\"nocase\">Subword</span> <span class=\"nocase\">Information</span>",
			"URL": "https://arxiv.org/abs/1607.04606v2",
			"language": "en",
			"author": [
				{
					"given": "Tomas",
					"family": "Mikolov"
				},
				{
					"given": "Armand",
					"family": "Joulin"
				},
				{
					"given": "Edouard",
					"family": "Grave"
				},
				{
					"given": "Piotr",
					"family": "Bojanowski"
				}
			],
			"type": "article-journal",
			"citation-label": "mikolov_enriching_2016",
			"id": "https://arxiv.org/abs/1607.04606",
			"issued": {
				"date-parts": [
					[
						2016,
						7
					]
				]
			}
		}
	},
	"https://www.mitpressjournals.org/doi/abs/10.1162/tacl_a_00051": {
		"fetched": "2019-08-04T15:57:47.701Z",
		"bibtex": "\n@article{bojanowski_enriching_2017,\n\ttitle = {Enriching {Word} {Vectors} with {Subword} {Information}},\n\tvolume = {5},\n\turl = {https://doi.org/10.1162/tacl_a_00051},\n\tdoi = {10.1162/tacl_a_00051},\n\tabstract = {Continuous word representations, trained on large unlabeled corpora are useful                     for many natural language processing tasks. Popular models that learn such                     representations ignore the morphology of words, by assigning a distinct vector                     to each word. This is a limitation, especially for languages with large                     vocabularies and many rare words. In this paper, we propose a new approach based                     on the skipgram model, where each word is represented as a bag of character                         n-grams. A vector representation is associated                     to each character n-gram; words being represented                     as the sum of these representations. Our method is fast, allowing to train                     models on large corpora quickly and allows us to compute word representations                     for words that did not appear in the training data. We evaluate our word                     representations on nine different languages, both on word similarity and analogy                     tasks. By comparing to recently proposed morphological word representations, we                     show that our vectors achieve state-of-the-art performance on these tasks.},\n\turldate = {2019-08-04},\n\tjournal = {Transactions of the Association for Computational Linguistics},\n\tauthor = {Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},\n\tmonth = dec,\n\tyear = {2017},\n\tpages = {135--146}\n}",
		"csl": {
			"title": "Enriching <span class=\"nocase\">Word</span> <span class=\"nocase\">Vectors</span> with <span class=\"nocase\">Subword</span> <span class=\"nocase\">Information</span>",
			"volume": "5",
			"URL": "https://doi.org/10.1162/tacl_a_00051",
			"DOI": "10.1162/tacl_a_00051",
			"container-title": "Transactions of the Association for Computational Linguistics",
			"author": [
				{
					"given": "Piotr",
					"family": "Bojanowski"
				},
				{
					"given": "Edouard",
					"family": "Grave"
				},
				{
					"given": "Armand",
					"family": "Joulin"
				},
				{
					"given": "Tomas",
					"family": "Mikolov"
				}
			],
			"page": "135-146",
			"type": "article-journal",
			"citation-label": "bojanowski_enriching_2017",
			"id": "https://www.mitpressjournals.org/doi/abs/10.1162/tacl_a_00051",
			"issued": {
				"date-parts": [
					[
						2017,
						12
					]
				]
			}
		}
	},
	"https://ai.google/research/pubs/pub46808/": {
		"fetched": "2019-08-04T16:02:04.549Z",
		"bibtex": "\n@inproceedings{cer_universal_2018,\n\taddress = {Brussels, Belgium},\n\ttitle = {Universal {Sentence} {Encoder}},\n\turl = {https://arxiv.org/abs/1803.11175},\n\turldate = {2019-08-04},\n\tbooktitle = {In submission to: {EMNLP} demonstration},\n\tauthor = {Cer, Daniel and Yang, Yinfei and Kong, Sheng-yi and Hua, Nan and Limtiaco, Nicole Lyn Untalan and John, Rhomni St and Constant, Noah and Guajardo-Céspedes, Mario and Yuan, Steve and Tar, Chris and Sung, Yun-hsuan and Strope, Brian and Kurzweil, Ray},\n\tyear = {2018}\n}",
		"csl": {
			"publisher-place": "Brussels, Belgium",
			"title": "Universal <span class=\"nocase\">Sentence</span> <span class=\"nocase\">Encoder</span>",
			"URL": "https://arxiv.org/abs/1803.11175",
			"container-title": "In submission to: EMNLP demonstration",
			"author": [
				{
					"given": "Daniel",
					"family": "Cer"
				},
				{
					"given": "Yinfei",
					"family": "Yang"
				},
				{
					"given": "Sheng-yi",
					"family": "Kong"
				},
				{
					"given": "Nan",
					"family": "Hua"
				},
				{
					"given": "Nicole Lyn Untalan",
					"family": "Limtiaco"
				},
				{
					"given": "Rhomni St",
					"family": "John"
				},
				{
					"given": "Noah",
					"family": "Constant"
				},
				{
					"given": "Mario",
					"family": "Guajardo-Céspedes"
				},
				{
					"given": "Steve",
					"family": "Yuan"
				},
				{
					"given": "Chris",
					"family": "Tar"
				},
				{
					"given": "Yun-hsuan",
					"family": "Sung"
				},
				{
					"given": "Brian",
					"family": "Strope"
				},
				{
					"given": "Ray",
					"family": "Kurzweil"
				}
			],
			"type": "paper-conference",
			"citation-label": "cer_universal_2018",
			"id": "https://ai.google/research/pubs/pub46808/",
			"issued": {
				"date-parts": [
					[
						2018
					]
				]
			}
		}
	}
}